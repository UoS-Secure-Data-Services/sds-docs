{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Secure Data Services &amp; Research Cloud Computing @ Sheffield","text":"<p>This is the documentation for The University of Sheffield's Secure Data Service and Research Cloud Computing platform.</p> <p>If you are currently attending TUOS and would like to know more about cloud computing for research please check out our Cloud Computing page on the website.</p>"},{"location":"#research-and-innovation-team","title":"Research and Innovation team","text":"<p>The Research and Innovation team in IT Services are the team responsible for the Secure Data Services, Research Cloud Computing platform, as well as all other aspects of research computing. If you require support with SDS, RCC, training or software for your workstations, the Research and Innovation team are happy to help. Take a look at the Research and Innovation website or email research-it@sheffield.ac.uk.</p>"},{"location":"DSH/","title":"Data Safe Haven (DSH)","text":"<p>This section of the documentation contains information about the differences between the DSH and RCC platform. As the DSH is a more controlled environment certain aspects of the system are different to the RCC platform.</p> <p>The diagram below shows the structure of the DSH from a users' perspective, together with a workflow through it. </p> <p></p> <p>After obtaining a login, the user first installs Amazon Workspaces onto their work machine (either Windows or Mac). This allows you to log into the Amazon Workspaces windows machine, and from here, create resources for their project using the Ronin web page.(1).</p> <p>Using the Ingress tool on the desktop of the user's Amazon Workspaces machine, a user can import data and the software the user needs into the project by uploading to a transient internet-accessible bucket(2).</p> <p>By using Ronin Link on the user's Amazon Workspaces machine, a user can connect to the machines created earlier to perform their research (3).</p> <p>Finally, using the egress application in the Amazon Workspaces machine, data can be exported to an egress bucket for checking (4). </p>"},{"location":"DSH/accessing-the-dsh/","title":"Accessing The DSH","text":"<p>Unlike in the RCC platform, the DSH requires you to access the system via a Bastion Host created specifically for your project. This comes in the form of a virtual desktop hosted in AWS WorkSpaces, for which you'll need software to access.</p>"},{"location":"DSH/accessing-the-dsh/#install-the-aws-workspaces-client","title":"Install The AWS WorkSpaces Client","text":"<p>Before proceeding, you'll need to ensure you have received conformation that your DSH account and workspace has been fully provisioned for use with your university account.</p> <ol> <li> <p>Open the Software Center, search for and ensure the \"Update Computer Certificate Acl\" application is available and installed:  </p> </li> <li> <p>Download the latest Windows client from the WorkSpaces website</p> </li> <li> <p>Run the WorkSpaces client installer, when prompted choose \"Install just for you\": </p> </li> <li> <p>If prompted with a prompt to install a new certificate for the <code>Starfield Services Root Certificate Authority (CA)</code> select <code>Yes</code> </p> </li> <li> <p>Follow through the rest of the prompts until the installer has finished</p> </li> </ol>"},{"location":"DSH/accessing-the-dsh/#connect-to-your-workspace","title":"Connect To Your WorkSpace","text":"<p>Note</p> <p>You will only be able to access your workspace via a University of Sheffield managed desktop while onsite (connected to the campus network).</p> <p>Attempting to connect while offsite, even while connected to the VPN will result in an authentication failure.</p> <p>During the account setup process you should have received an email containing the registration code for your WorkSpace. Once you open the WorkSpaces app on your machine enter the registration code as prompted:</p> <p>You should then be prompted with to enter your DSH credentials:</p> <p>Here you will enter your <code>dsh_</code> username and password. In the MFA field you will need to obtain a one time code from your Duo app:</p> <p>Once you have entered the MFA code make sure to press the <code>Refresh Passcode</code> button as these are one time use only.</p> <p>When you sign into your WorkSpace for the first time you may be prompted with a firewall security alert:</p> <p>You can safely cancel off this page.</p> <p>The WorkSpace should now start up and connect after a few minutes. If you encounter any issues during this process please take a look at the troubleshooting steps below.</p>"},{"location":"DSH/accessing-the-dsh/#troubleshooting","title":"Troubleshooting","text":"<p>The most common error while entering your registration code is the \"Unable to authenticate\" screen:</p> <p>This may appear when the device you are connecting with is not authorized to register with your WorkSpace. Potential causes:</p> <ul> <li>Attempting to connect with an un-managed device (When connecting you   will need to do so from a university provided managed YoYo desktop)</li> <li>Computer certificate inaccessible (Ensure step 3. of the   install-aws-workspaces-client   section has been followed)</li> </ul> <p>If neither of these apply and the issue persists, or if there are any other issues please log a helpdesk ticket.</p>"},{"location":"DSH/accessing-the-dsh/#understanding-your-access","title":"Understanding Your Access","text":"<p>Now that you have a way into the DSH, you should familiarize yourself with the different things you can and cannot access via your WorkSpace.</p> <p>The diagram above shows a simplified layout of your access in the DSH. From your workspace you will be able to access:</p> <ul> <li>Ronin</li> <li>Machines/Instances in your project/s</li> <li>Internal Gitlab</li> <li>Internal update mirrors</li> <li>Authentication services</li> </ul> <p>Machines/Instances in your projects/s will have additional access to things like:</p> <ul> <li>Object Storage</li> <li>Internal CRAN / Pypi mirrors</li> <li>Unrestricted access to each other (machines in your projects have no   firewalls between each other)</li> </ul>"},{"location":"DSH/accessing-the-dsh/#ronin","title":"Ronin","text":"<p>Your workspace will come pre-configured with Firefox as the default browser. It is configured to automatically take you to the Ronin web UI as the default home page.</p>"},{"location":"DSH/accessing-the-dsh/#machinesinstances","title":"Machines/Instances","text":"<p>Access to your instances will be done through the Ronin Link desktop application. Allowing you to connect to both Windows and Ubuntu machines with either SSH or remote desktop.</p>"},{"location":"DSH/accessing-the-dsh/#object-storage","title":"Object storage","text":"<p>Access to object storage you create in your project is limited to the instances you assign permissions to. You won't be able to access a bucket from your instance even with valid credentials until it is given additional permissions to do so.</p>"},{"location":"DSH/accessing-the-dsh/#external-services","title":"External Services","text":"<p>Certain projects may be granted special access outside of the DSH's firewall, this is primarily restricted to things like licensing servers.</p>"},{"location":"DSH/data-ingress/","title":"Data Ingress","text":"<p>This document is focused on external data ingress methods supported by the RCC platform. If you are an internal user looking to upload data to the platform you may wish to look at other available methods available to you such as Object Storage</p>"},{"location":"DSH/data-ingress/#sftp","title":"SFTP","text":"<p>Info</p> <p>The SFTP service is made available to approved data providers upon request, if you've not been explicitly pointed towards using this service then you most likely don't have access. Access is provided on a project by project basis depending on data sharing agreements.</p> <p>If this service looks like a good fit for your needs please get in touch with us via the IT Services Helpdesk or if you are an external data provider please reach out to your UoS contacts.</p> <p>The docs here are broken up into Uploading and Accessing data, with the former aimed at both internal and external 3rd parties looking to upload data into the system and the latter aimed at internal users looking to access this uploaded data within the system.</p>"},{"location":"DSH/data-ingress/#uploading-data","title":"Uploading Data","text":"<p>This section of the docs is aimed at those looking to upload data to the SFTP service. The process is broken down into two steps:</p> <ul> <li>Generating credentials to be used to access the system</li> <li>Connecting and uploading data</li> </ul>"},{"location":"DSH/data-ingress/#generating-keys","title":"Generating Keys","text":"<p>Should you be granted access to the service you'll need to generate an RSA or ECDSA key pair, and forward the public key to your internal contact.</p> WindowsMac/Linux <p>We suggest you use PuTTYgen to generate keys on Windows machines. This is included in the full installer of Putty found here.</p> <p>From PuTTYgen select either <code>EdDSA</code> or <code>RSA</code> as the type of key to generate, then click on \"Generate\":</p> <p></p> <p>With the key generated we highly recommend you enter a strong password in the key passphrase fields before saving the private key. As the name suggests this key is private and should not be shared with anyone!</p> <p>You'll also want to save the public key, this is the file you'll need to send on to your internal contact.</p> <p>Mac and Linux machines come with the <code>ssh-keygen</code> command baked in and can be used here to generate the keys we require.</p> <p>Run the below via a terminal replacing <code>&lt;key-name&gt;</code> with a filename of your choosing. You may wish to <code>cd</code> into a suitable directory first.</p> <pre><code>ssh-keygen -t ed25519 -f &lt;key-name&gt;\n</code></pre> <p>This command will ask you to enter a passphrase for the key, we highly recommend you do so.</p> <p>Once this has been entered the system will generate 2 new files, your private key is the file with the name you specified after the <code>-f</code> and the public key which is the same again but suffixed with <code>.pub</code></p> <p>Take care to keep your private key safe as it should not be shared with anyone! The <code>&lt;key-name&gt;.pub</code> file should be forwarded onto your internal contact.</p>"},{"location":"DSH/data-ingress/#connecting","title":"Connecting","text":"<p>Once you've been given the green light that your account has been created with the public key you've provided from the steps above you'll want to connect into the service to start transferring data.</p> <p><code>sftp.rcc.shef.ac.uk</code> via port <code>22</code> is the primary endpoint for accessing the service. Use this when configuring the server address and port with the software suggested below.</p> WindowsMac/Linux <p>Although we're tool agnostic this document providing step by step guidance for WinSCP. Should you feel confident with configuration other good tools such as FileZilla will work just fine.</p> <p>You'll first need to change some settings in WinSCP:</p> <p>Open the preferences dialogue box from the Options menu in the top right.</p> <p> </p> <p>From here navigate to the \"Transfer\" tab, select \"Default\" and \"Edit...\":</p> <p> </p> <p>This will open the \"Transfer settings\" box, from here ensure the \"Preserve timestamp\" box is unchecked:</p> <p> </p> <p>After confirming the transfer settings, enter the \"Endurance\" tab below and set the \"Enable transfer resume/transfer to temporary filename for\" setting to \"Disable\":</p> <p> </p> <p>With these now set you may need re-open WinSCP to see the <code>Login</code> form, once open you'll want to make sure that the file protocol <code>SFTP</code> is selected:</p> <p> </p> <p>With the server address entered in the host name and user name fields entered in you'll want to click on the <code>Advanced...</code> button to select your private key.</p> <p> </p> <p>From the left hand side of this new menu go to the <code>SSH - Authentication</code> tab and under the text box for <code>Private key file:</code> click on the <code>...</code> button to open a file selection prompt. This will allow you to select the private key <code>.ppk</code> file you generated in the steps above. </p> <p>With those filled you should now be able to log into the SFTP service.</p> <p>We don't yet have specific guidance on connecting to the SFTP service via Mac or Linux machines, however there are many good tools out there that we're happy to suggest:</p> <ul> <li>Cyberduck for Mac</li> <li>FileZilla for Linux or Mac</li> </ul>"},{"location":"DSH/data-ingress/#accessing-data","title":"Accessing Data","text":"<p>If you are a user of the system now looking to access the data uploaded to the SFTP service read on.</p> <p>When data is uploaded to the SFTP service the data will be placed inside of a new bucket within your project given the name <code>&lt;PROJECT NAME&gt;-ingress</code> like shown below:</p> <p>Warning</p> <p>A bucket with this prefix is created whenever one of our ingress systems is used and one does not already exist. If you have already created a bucket with this naming structure be warned that these services will interact with the bucket.</p> <p>Data uploaded to the SFTP service will be placed into a folder at the top level called <code>SFTP</code>, within that sub-folders will be created for each user of the service assigned to your project, these will be given the name of the user that uploaded the data.</p> <p>The upload process to the SFTP service is a one way system, that means that data that comes into the system cannot go out this way. For example if you were to upload data into this bucket it will not be made accessible to the SFTP users. At a technical level objects within the ingress bucket are air-gapped from the SFTP users.</p> <p>Note</p> <p>You are free to use the ingress bucket however you would any other bucket within your project, just be aware that various mechanisms within the RCC service has access into these buckets to place ingress data into.</p>"},{"location":"RCC/","title":"Research Cloud Compute (RCC)","text":"<p>This section of the documentation details the known issues, limitations and considerations around the RCC platform.</p> <p>Information on the Ronin platform itself can be found in it's own section Ronin.</p> <p>Warning</p> <p>Although RCC is currently free-at-point-of-use projects are assigned budgets, therefore the documentation here will explain ways in which to make optimal use of the services provided.</p>"},{"location":"RCC/budgets/","title":"Budgets","text":"<p>Although RCC is currently free-at-point-of-use, all projects are assigned budgets. So why is that important to you?</p> <p>At project creation we'll estimate a sensible budget based on your project length and predicted compute &amp; storage requirements, that's not to say you'll be restricted once you hit the budget limit.</p> <p>By default all projects that hit their budget go into something called \"auto pause\", this will stop all running instances in the project. This is mostly in place to prevent accidental over usage.</p> <p>Note</p> <p>When auto pause triggers, there is nothing stopping you from going in and starting your machines back up!</p> <p>Both project users and system administrators will be notified of your budget approaching and/or hitting its limit / end date.</p> <p>We'll usually contact you when this happens to make sure things are on track and if needed, extend the budget / project timeline.</p>"},{"location":"RCC/budgets/#project-dashboard","title":"Project dashboard","text":"<p>At a glance your project dashboard has a periodically updated budget breakdown that will try to forecast based on your usage at the time. It's important to note that this is not always up-to date.</p> <p>If you've poked around Ronin already you'll note that when creating resources there's usually a \\$/h or \\$/m metric paired along with it, these are all things that will eat into your budget and eventually end up on the dashboard.</p> <p>Tip</p> <p>There is a small \ud83d\udd63 icon at the right hand side of your dashboard budget, click this and you'll see the exact time the information was updated.</p>"},{"location":"RCC/budgets/#machines","title":"Machines","text":"<p>When creating a machine in Ronin it will give you a breakdown of costs as you size the instance. This usually boils down to a cost per hour to run the instance and cost per month for the underlying attached storage (which is handily calculated in the hourly charge).</p> <p>Warning</p> <p>Although storage costs are shown in the hourly usage this is actually a flat monthly rate based on the storage type and size.</p> <p>Which means when the instance is turned off you wont be charged for the compute but will still be charged for the storage!</p> <p>With a machine created, the costs for the instance will show up in the $ tab of its panel:</p> <p></p> <p>As noted above the instance in a running state will cost more per month than in the stopped state, but there will still be some charge with it in the stopped state.</p>"},{"location":"RCC/budgets/#object-storage","title":"Object storage","text":"<p>Unlike block storage attached to machines where you set a disk size and are charged for that size, object storage charges you per GB of space used.</p> <p>Calculating S3 storage costs can be a bit daunting when viewed from the AWS documentation: https://aws.amazon.com/s3/pricing/ In any event object storage will always be the most cost effective method of storing data within RCC.</p> <p>Storage costs for your data in object storage is updated every 72 hours and shown in the project dashboard:</p> <p></p> <p>You'll note that this is broken down into standard and archived objects, but only gives an aggregated cost for all of your stored objects.</p> <p>Note</p> <p>Archival storage costs less to store the data but may incur additional charges to retrieve the data. See <code>object-archiving</code>{.interpreted-text role=\"ref\"} for more info.</p>"},{"location":"RCC/known-issues/","title":"Known Issues","text":"<p>Here you will find a list of known issues, causes and potential workarounds/fixes. If you're facing an issue not mentioned here or in the Limitations &amp; Considerations page, please get in touch via the IT Services Helpdesk.</p>"},{"location":"RCC/known-issues/#windows-machines","title":"Windows Machines","text":"<p>Unlike the available Linux distributions, Windows Sever is more resource intensive and usually takes longer to become available. This has led to confusion in some cases.</p>"},{"location":"RCC/known-issues/#unable-to-connect-to-new-machine","title":"Unable to connect to new machine","text":"<p>Problem: Upon creation of a machine, Ronin shows the instance as \"Available\" however the system may be inaccessible via Ronin Link or SSH.</p> <p>Solution: The typical issue is that Windows servers take a little while longer to start up as opposed to Linux. The machine should be available after about 5 minutes from creation. Avoid restarting the machine during this time. If it should not become available after 10+ minutes please contact support.</p>"},{"location":"RCC/known-issues/#unable-to-connect-to-machine-reoccurring","title":"Unable to connect to machine - Reoccurring","text":"<p>Problem: I'm having issues connecting to my instance, even though I might have been able to connect earlier.</p> <p>Solution: In some edge cases windows passwords have been reset by the system, making them inaccessible even if you've managed to connect before. To fix this open up the Ronin UI and perform a password reset on the machine.</p>"},{"location":"RCC/known-issues/#slowunresponsive-desktop-session","title":"Slow/Unresponsive desktop session","text":"<p>Problem: I have a machine and have connected into the desktop via Ronin Link, however it is painfully slow!</p> Initial start-up time average: 25 minutes Initial start-up time average: 10 minutes <p>Solution: The most likely scenario here is that the instance type chosen is simply unfit for purpose. Unlike the available Linux distros, Windows usually likes to have more power. Try selecting a bigger instance type when creating the machine. This usually links back to the first problem as it is exacerbated by the lower performance.</p> <p>Note</p> <p>This is the RCC platform after all, we encourage you to use the big computers!</p>"},{"location":"RCC/known-issues/#ubuntu-machines","title":"Ubuntu Machines","text":"<p>Problem: Connecting to a remote desktop session gets stuck in a loop after trying to install.</p> <p></p> <p>Cause: Ronin Link creates a desktop environment by SSHing into the target machine and running the installation step by step, these commands all originate from the machine running Ronin Link.</p> <p>If at any point in the install the connection is broken (i.e. Network connectivity is lost) then there is potential for the installer to break and soft lock future attempts.</p> <pre><code>clear-both\n</code></pre> <p>Solution: If the machine is brand new it might be easier to terminate the instance and try again with a new machine. If you need to access the machine it should still be available over SSH, although if access over the desktop environment is a must please get in touch via the IT Services Helpdesk.</p> <p>Problem: Connecting to a remote desktop session opens a new screen but doesn't show anything.</p> <p></p> <p>Solution: Close the session window and try to connect again. Most of the time this is enough to get the session to connect and most commonly happens with brand new instances.</p> <p>Note</p> <p>An easy way to know if the session is working is that there will be a spinning circle to indicate the session is connecting.</p>"},{"location":"RCC/limitations-considerations/","title":"Limitations / Considerations","text":"<p>Through the pilot phase there will be aspects of the system that may be partially available or come with limitations/considerations.</p>"},{"location":"RCC/limitations-considerations/#gpu-backed-machines","title":"GPU Backed Machines","text":"<p>Ronin provides access to a handful of GPU backed AWS instances, given there are so many options we've decided to keep to providing one pre-configured package.</p> <p>The \"Ubuntu 22.04 LTS - NVIDIA Drivers\" package comes with drivers and software pre-configured to work with Ronin's remote desktop solution Nice DCV, allowing you to skip the somewhat tedious configuration steps.</p> <p>Note</p> <p>If you choose to use the standard Ubuntu package with a GPU backed machine and install the desktop environment via Ronin Link you may find that the remote session is not making use of the GPU.</p> <p>Take a look at the Nice DCV docs for further info.</p>"},{"location":"RCC/limitations-considerations/#changing-instance-type-after-creation","title":"Changing Instance Type After Creation","text":"<p>In the event you make use of the \"Ubuntu 22.04 LTS - NVIDIA Drivers\" package at initial startup the machine will configure itself with the available GPU/s.</p> <p>It may be the case that your workload changes overtime making it necessary to increase or decrease the instance size, adding or removing GPUs.</p> <p>So that the DCV config can pick up on these changes you should run the commands below following an instance type change:</p> <pre><code>nvidia-xconfig --preserve-busid --enable-all-gpus\nsed -ie '/Section \"Device\"/a \\ \\ \\ \\ Option     \"HardDPMS\" \"false\"' /etc/X11/xorg.conf\n\nsystemctl isolate multi-user.target\nsystemctl isolate graphical.target\n\nreboot\n</code></pre>"},{"location":"RCC/networking/","title":"Networking","text":"<p>When you are given access to the RCC platform it will come in the form of one or more \"Projects\" presented inside of Ronin. Resources you create inside of these projects have differing levels of network access and accessability.</p> <p>For the most part you will be working with what Ronin calls Machines and what we call Instances, these resources are placed into their own project specific subnet. This is a way for Ronin to allow instances in a project to communicate with one another in a isolated manner.</p>"},{"location":"RCC/networking/#intended-usage","title":"Intended Usage","text":"<p>It is important to understand that RCC is not designed to host services accessible to the outside world or campus for that matter. You can however have host services designed to be accessed by other instances in your project or locally to yourself.</p> <p>You can make use of the Ronin Link \"Connect to an Application\" feature to proxy applications directly to the machine you connect in on, this makes it as if the service were running locally.</p>"},{"location":"RCC/networking/#architecture","title":"Architecture","text":"<p>Instances in your project/s have unrestricted access other instances in the same project, have access to the campus network and from there outbound to the web. The graphic below goes into more detail:</p> <p>Note</p> <p>Only outbound networking from a project subnet is unrestricted. Inbound access to the Ronin Instances is limited to SSH over port 22 TCP from the university VPN.</p>"},{"location":"RCC/notifications/","title":"Notifications","text":"<p>As a creator / owner of resources inside Ronin you may receive Email based notification depending on their state. These intend to alert you of possible under utilization of resources to help avoid unnecessary project spend.</p> <p>Note</p> <p>All notifications will come from the address noreply@ronin.cloud, always be cautious when following links from external addresses!</p>"},{"location":"RCC/notifications/#instance_utilization","title":"Instance Utilization","text":"<p>If you have received an email titled \"Ronin Under Utilization Alert!\" this means that Ronin has noticed an Instance in your project has gone for more than more than 24 hours with under 10% CPU utilization. This is designed to ensure you've not accidentally left a machine running idle. Unlike on-premise VMs that run 24/7 we recommend you shut down your instances when not in use, much like you would your own PC.</p> <p>Only instances that are running are subject to the hourly usage rates however you will still be charged for the provision of storage as is explained below.</p> <p>We do also understand this alert could be a false positive where your workloads are not CPU demanding but still require the machine be on for extended periods. If this is the case please get in touch and we can make the instance exempt from these alerts.</p>"},{"location":"RCC/notifications/#unused_drive_storage","title":"Unused Drive Storage","text":"<p>If you have received an email titled \"Unused Drive Storage Detected\" this means that Ronin has noticed detached drives have been in your project for extended periods.</p> <p>This could be from a terminated instance that had the \"Keep On Termination\" flag set:</p> <p>Or volumes that were detached and forgotten etc...</p> <p>As provisioned volumes are charged for based on how much storage is requested it's best practice remove unused storage once it's no longer required. For long term and/or bulk data storage we recommend you use <code>object-storage</code></p>"},{"location":"REDCap/","title":"REDCap (Research Electronic Data Capture)","text":"<p>This page contains information regarding the University of Sheffield's instance of the University of Vanderbilt's REDCap software.</p> <p>This service may be unavailable due to maintenance (typically service upgrades) on Mondays 09:00 - 10:30. Users will be notified by email the week before if there will be maintenance that requires downtime during that time window. Users will also be notified when maintenance work has been completed.</p> <p>For more information on this REDCap service, please contact the SDS team by email at research-it@sheffield.ac.uk</p> <p>Warning</p> <p>REDCap is currently under evaluation at the University of Sheffield and no decision has been made as to its future.</p>"},{"location":"Ronin/","title":"Ronin","text":"<p>Ronin is the frontend user interface that connects researchers up to the AWS backed infrastructure. It's used in both RCC and DSH to slightly different effect:</p> <ul> <li>Ronin in RCC makes use of Ronin Core</li> <li>Ronin in DSH makes use of Ronin Isolate</li> </ul> <p>The subtle differences between the two allow us to provide a more locked down experience in the DSH (allowing us to hold more sensitive data) whereas RCC allows for a simpler user access experience without compromising on overall security.</p>"},{"location":"Ronin/#existing-documentation","title":"Existing Documentation","text":"<p>The team over at Ronin have already built out a plethora of useful docs that may be relevant to you, so why not head on over to the RONIN BLOG</p> <p>Here are a few notable examples to get you up and running:</p> <ul> <li>Creating a machine in Ronin</li> <li>Selecting a machine type</li> <li>Connecting to machines in Ronin</li> <li>Working with object storage</li> <li>Managing storage drives</li> <li>Project storage summary</li> </ul> <p>Once you've gotten through those we've got some further details on how and what is accessible to you within RCC platform:</p>"},{"location":"Ronin/backup-restore/","title":"Backup and Restore","text":"<p>As the RCC &amp; DSH platforms are built upon AWS we're making use of the automated backup systems they provide. As such you are able to make use of these features in the event of data loss / corruption to restore from an alternate point in time.</p> <p>Backup and restoration is split out into 'Machine' and 'Object Storage' as the data stored is handled differently for each. Machines are backed up and restored in full at a single point in time whereas object storage is much more granular, allowing you to restore to specific versions and at an individual object level.</p>"},{"location":"Ronin/backup-restore/#backup-schedule","title":"Backup Schedule","text":"<p>Backup jobs are scheduled to start at 00:00 GMT, however they have an 8 hour starting window, meaning that the time of the backup could be anywhere between 00:00 GMT and 08:00 GMT.</p> <p>When restoring a machine you will always know the time of the backup as it is labelled on the package down to the minute.</p>"},{"location":"Ronin/backup-restore/#backup-retention","title":"Backup Retention","text":"<p>Retention in a backup context is the amount of time we keep backups for and how frequently we create backups (their granularity).</p> <p>In a perfect world this would be indefinite, however the more backups we keep the more data is kept and therefore cost increases.</p>"},{"location":"Ronin/backup-restore/#machine-backups","title":"Machine backups","text":"<p>We currently keep machine backups with the following retention:</p> <ul> <li>14 daily backups</li> <li>8 Weekly backups</li> </ul> <p>This means you can go 2 months back in time with weekly increments, or 2 weeks with daily increments.</p>"},{"location":"Ronin/backup-restore/#object-storage-bucket-backups","title":"Object Storage / Bucket backups","text":"<p>Bucket backups follow the same retention policies as machine backups.</p> <p>Data in your object storage is backed up using 'versioning'. This feature is automatically enabled for you at creation of a new bucket along with the creation of a lifecycle rule. Should you wish to know more we recommend you read our docs on object storage</p> <p>Note</p> <p>Although versioning is required for our backup policy to work (which is why it is enabled for you by default) object versions are not correlated with object backups. Read on to <code>restoring_s3_objects</code>{.interpreted-text role=\"ref\"} for more information on how this effects restoration of objects.</p>"},{"location":"Ronin/backup-restore/#restoring_machines","title":"Restoring Machines","text":"<p>Restoration of machines is a 2 step process. Step 1. is to log a helpdesk ticket requesting a Ronin machine restore, for this we will need to know:</p> <ul> <li>The machine name as presented in Ronin</li> <li>Potential restore date/s</li> </ul> <p>After this information has been sent over you will receive a response once access to the requested backup/s have been added.</p> <p>As automated backups show up as Ronin Packages a restore can be performed by creating a new machine and searching the \"Project Packages\" section under Step 1 of the machine creation screen.</p> <p>Here you may find that there is a mix of your own self created <code>project packages&lt;Package&gt;</code> and the backups you've requested access too. If you have a lot of machines it can become a little difficult to see the wood for the trees.</p> <p>It's usually best to use the search function at the top right to find the name of the machine you are looking to restore.</p> <p>Once you have found your target machine in the list, select one that has a date of creation you're happy with (you may wish to go further back in time), close the packages window and continue as if you were going to create a new machine.</p> <p>What you have essentially done here is clone a machine from a set point in time. You may even still have the source machine running while this is happening.</p> <p>After all is said and done you should now have a freshly restored machine.</p> <p>Warning</p> <p>As your restored machine is being spun up background tasks will kick in to make sure that it is up-to date. This ensures machines that have been restored from months old backups have the latest updates applied immediately.</p> <p>You may find that the machine reboots itself one or more times without warning shortly after creation.</p> <p>Windows Renaming</p> <p>If your restored machine is running the Windows family of OSes you'll find that the computer name gets '-restored' suffixed to avoid naming conflicts as you may still have the source machine running in your project. Depending on how the machine and its software has been configured, it may not be advisable to have source and restored machines running at the same time.</p>"},{"location":"Ronin/backup-restore/#restoring_s3_objects","title":"Restoring From Object Storage","text":"<p>With versioning enabled any changes to a file after its initial creation will form a new version, allowing you to browse through the old ones should you need to revert to an earlier point in time.</p> <p>Hint</p> <p>The best place to learn about versioning is via the AWS documentation on versioning itself.</p> <p>Should you be using Cyberduck their documentation on versioning may also help.</p> <p>Versioning enables something of a self-service restore, more of a quasi-backup and not what we'd consider fool-proof. For that reason we also keep backups of your data in a vault not accessible to end-users.</p> <p>In the event you are not able to restore your files to an earlier point in time using versioning, or are having issues with versioned files please get in touch via the IT Services Helpdesk.</p>"},{"location":"Ronin/drive-storage/","title":"Drive Storage","text":"<p>Drive storage, or 'block storage' as it's sometimes more generally referred to as, is the storage attached directly to your instances within Ronin. The other main type of stored available in Ronin is object storage. Drive/block storage offers better performance for both reading/writing data and also for file metadata queries, but object storage is cheaper and offers larger capacities.</p> <p>These are most commonly the 'Root Drive' however Ronin gives you the option to create your own additional drive/block storage devices that can be attached to instances and moved between instances.</p> <p>Further Reading</p> <p>Should you want to know about the nitty gritty, the underlying technology used here is AWS EBS.</p>"},{"location":"Ronin/drive-storage/#drive_types","title":"Drive Types","text":"<p>When creating a new non-root drive, Ronin gives you multiple options for drive types. As a general rule of thumb we recommend you select SSD, this is due to how AWS provisions drive speed.</p> <p>The SSD drives will be allocated 125 MiB/s of read and write performance and 3000 of IOPS (as per gp3 defaults). Should your workload require more performance please do get in touch.</p> <p>For those wondering why we omit the other drive options, this is mainly due to the behavior of the magnetic storage classes. The HDD storage classes base their throughput off the provisioned storage size see here. Because of this we recommend that you use object storage for storing large amounts of data.</p>"},{"location":"Ronin/object-storage/","title":"Object Storage / S3","text":"RCCDSH <p>Object Storage created on the RCC platform has similar access restrictions to the instances. To access Ronin object storage (other than from a Ronin instance) you will need to be connected to the university VPN.</p> <p>For those unfamiliar, object storage in Ronin is very much like shared storage, behaving like folder for you to store and retrieve files from multiple different computers. The most notable difference with object storage is that you don't generally have it mounted to your computer like an additional drive.</p> <p>Object Storage within the DSH platform is much more restrictive than that of RCC Buckets created within projects still require you to create either read &amp; write or readonly keys but they also require you to assign an instance permission to access the bucket</p> <p>Furthermore the bucket is restricted to your DSH project, you cannot provide access between projects or outside of the DSH. This includes access outside of the DSH (IE: via the campus network or the wider internet)</p> <p>Info</p> <p>The term \"object\" used here is synonymous with the term \"file\"</p>"},{"location":"Ronin/object-storage/#creating-managing-deleting-object-storage","title":"Creating, Managing &amp; Deleting Object Storage","text":"<p>Creating a new bucket is as simple as navigating to a project and then \"Object Storage\" page via the right hand menu:</p> <p>From here you can view and manage exiting buckets as well as create new ones with the \"NEW OBJECT STORE\" button:</p> <p>Which will then present present a new field for you to name your object storage. This will need to be a unique name to Ronin as a whole, so bear in mind someone else may already have taken the name you want.</p> <p>In the event that this is the case you will be presented with an error message prompting you to use an alternative name.</p> <p>Once a suitable name has been used the new bucket should show up in the list ready for you to configure to further suit your needs.</p> <p>You may note that after a bucket's creation there are a handful of red lights and text, these are here to denote that features are turned off or yet to be configured. The steps below detail what each does and how / why you might want to configure them.</p>"},{"location":"Ronin/object-storage/#creating-managing-keys","title":"Creating &amp; Managing Keys","text":"<p>Access keys are the primary method of authenticating with your object storage, they can be thought of like a username and password where:</p> <ul> <li>AccessKeyId = Username</li> <li>SecretAccessKey = Password</li> </ul> <p>Unlike a username / password pair however we do not get to manage them, instead they are generated for us. To do this click on the \"MANAGE PERMISSIONS\" button along the bottom of the bucket you wish to manage.</p> <p>You will then be presented with the option to generate either \"Read &amp; Write\" or \"Read Only\" keys. This refers to the level of permissions the given to the keys we generate.</p> <p>\"Read &amp; Write\" keys are allowed to:</p> <ul> <li>Access files &amp; folders (read)</li> <li>Modify files &amp; folders</li> <li>Create new files &amp; folders</li> <li>Delete files and folders</li> </ul> <p>\"Read Only\" keys are as you can probably surmise can only access files and folders within the bucket.</p> <p>Note</p> <p>Both keys are also given access to read all file versions if the feature is enabled on the bucket</p> <p>When you have selected which type of key you are looking to generate and click either of the \"Create Key\" buttons you will see a [.csv]{.title-ref} file with the name of your bucket downloaded to your computer.</p> <p>This file contains the generated AccessKeyId and SecretAccessKey mentioned earlier. You'll want to keep this safe and secure as they are the only copy of the key.</p> <p>If the SecretAccessKey part is lost new keys will have to be generated, this is simple enough as the option will present itself in the manage permissions window of your bucket. You will also note that you have the option to delete the keys and see the AccessKeyId to verify it is the correct key pair.</p> <p>With keys in hand you are now ready to connect to the bucket, see <code>accessing-object-storage</code> for details.</p>"},{"location":"Ronin/object-storage/#versioning","title":"Versioning","text":"<p>Normally when a new bucket is created versioning is disabled by default. We however enforce versioning inside Ronin as it is a requirement for backups.</p> <p>When you create a new bucket in Ronin you may even see this temporarily in the GUI, given a short period of time you'll note the versioning label on a new bucket turn from Red to Green:</p> <p>You will also note that a default version lifecycle of 14 days is set. This can be altered should you wish to extend or reduce the version lifecycle.</p> <p>What this means for you, adding, removing and editing objects in the bucket in day to day use will mostly be transparent.</p> <p>The most important effect is that when you overwrite existing files in the bucket the old \"version\" of that file rather than being replaced is hidden as an invisible file, becoming an \"old version\" You are then able look back into the past so to speak to see these versions. These versions are kept based on the lifecycle set for the bucket, by default any versions older than 14 days are deleted.</p> <p>Further Reading</p> <p>To understand more about how versioning works the AWS documentation on versioning is the best place to look.</p> <p>Though a useful tool, versioning comes with some caveats that might catch you out once in a while. Here are a few you might want to be aware of:</p> <ul> <li>Deleted files don't actually get deleted, but are given a delete   marker   to hide them from view.</li> <li>When a file large or small is changed, regardless of frequency a new   version is created in its place, these are kept until they hit the   lifecycle age. Many versions of an object will appear as though you   are being charged for having duplicates of the object. You may wish to   lower the lifecycle rules if this is the case, or perhaps move your   storage onto another more suitable location such as EBS.</li> <li>Before you can delete a bucket all files, versions and delete markers   must be removed. With versioning this becomes a complex enough task to   warrant it's own section.</li> </ul> <p>Note</p> <p>Versioning is enforced in RCC. Though the GUI shows the option to \"SUSPEND VERSIONING\", when attempted versioning will simply re-enable itself. This is due to the requirement for versioning to be enabled for our backup system to work.</p>"},{"location":"Ronin/object-storage/#archiving","title":"Archiving","text":"<p>Enabling an archiving lifecycle to your bucket may be suitable if you are going to be uploading extremely large datasets and have worries about storage costs. Object storage is already the best place to store large datasets when it comes to price, however archiving allows you to lower costs even more by moving objects of a pre-defined age to S3 Glacier.</p> <p>This is under the assumption that the data over the defined age will be accessed less frequently (sometimes considerably) than newer data.</p> <p>As with anything there are caveats to this, the deeper the tier of archival you choose the lower storage costs you pay. To balance out these lower storage costs you will need to pay more to retrieve archived data and in some cases even wait extended periods of time to access it.</p> <p>As usual the best place to learn the fine details is in AWS's documentation. The S3 Glacier storage classes page has a breakdown of the differing archival tiers available for use in Ronin.</p> <p>If you think that Glacier archival is right for you, but are still unclear on the potential implications please get in touch via the IT Services Helpdesk.</p>"},{"location":"Ronin/object-storage/#deleting-a-bucket","title":"Deleting a Bucket","text":"<p>As explained in the <code>object-versioning</code> section, when files are deleted from a bucket in RCC they aren't really deleted. Simply given a delete marker which in turn will hide the object from view.</p> <p>This along with object versions (which are typically also hidden from view) complicates the deletion of a bucket, given that they must also be removed before the bucket can be deleted.</p> <p>There are a couple ways to go about this. The simplest and least involved method would be to change the version settings on the bucket to a lifecycle of 1 day, then simply wait 24 hours and the lifecycle rule will remove the old versions for you.</p> <p>Should you not have the time to wait for this however, you will need to manually delete versions and object markers from the bucket via the AWS CLI. With the AWS CLI installed and configured using your bucket access keys, you'll want to use the below commands to first delete all object versions and then delete markers from the bucket:</p> <p>Info</p> <p>These commands rely on you having AWS CLI installed, have collected the full bucket name and <code>endpoint-url</code> from within the Ronin UI. See Accessing Object Storage for info on how to find this.</p> Delete Versions<pre><code>aws s3api delete-objects --bucket &lt;BUCKET NAME&gt; \\\n  --delete \"$(aws s3api list-object-versions --bucket &lt;BUCKET NAME&gt; \\\n  --query='{Objects: Versions[].{Key:Key,VersionId:VersionId}}')\" \\\n  --endpoint-url &lt;SERVER URL&gt;\n</code></pre> Delete 'Delete markers'<pre><code>aws s3api delete-objects --bucket &lt;BUCKET NAME&gt; \\\n  --delete \"$(aws s3api list-object-versions --bucket &lt;BUCKET NAME&gt; \\\n  --query='{Objects: DeleteMarkers[].{Key:Key,VersionId:VersionId}}')\" \\\n  --endpoint-url &lt;SERVER URL&gt;\n</code></pre> <p>Warning</p> <p>These commands will delete ALL versions and delete markers in the bucket!</p> <p>Source: https://www.learnaws.org/2022/07/04/delete-versioning-bucket-s3/</p> <p>With that done you should now be able to delete the bucket from within the Ronin GUI.</p>"},{"location":"Ronin/object-storage/#accessing-object-storage","title":"Accessing Object Storage","text":"<p>As mentioned previously access to your object storage from outside the machines in your project is restricted to the VPN. This restriction has an impact on how you access the buckets as you need to specify an alternate S3 endpoint to the public AWS servers, this endpoint being something only accessible via the VPN.</p> Windows / Mac - CyberduckLinux - AWS CLI <p>Cyberduck is a free to use application available on Windows and Mac, suggested for use by Ronin with some handy direct integration to make connecting to your object storage easier.</p> <p>Hint</p> <p>Cyberduck comes pre-installed on the Windows images provided in Ronin</p> <p>If your wanting to use Cyberduck on your own machine simply install the relevant version on your machine from their site https://cyberduck.io/download/</p> <p>Though not Linux specific as the AWS CLI will work on any of the operating systems mentioned, we suggest this here as there are fewer alternate solutions for Linux.</p> <p>Firstly you'll want to follow the instructions found here: Installing or updating the latest version of the AWS CLI And suggest you read through the Quick Setup page to get a firm understanding of the CLI tool.</p> <p>Before you can run any CLI commands you'll need to ensure you've logged in.</p> <p>You'll want to use the keys generated for your bucket during the quick setup along with the default region of <code>eu-west-2</code> The region information can also be seen in the \"CONNECT INFO\" page of your bucket:  </p> <p>To form our CLI commands we'll a couple more pieces of the puzzle these also happen to be available in the connection info page.</p> <p>At the top is the Server URL, we'll be adding this server url onto any command we issue to S3, we do this via the <code>--endpoint-url</code> flag. If it is forgotten you'll probably end up with an \"Access Denied\" style error. At the bottom is the Path to our S3 bucket (This is also the full bucket name), we'll be appending this to <code>s3:\\\\</code> in our commands as a way to point to the bucket.</p> <p>An example command to upload the <code>data.txt</code> file from my current working directory to an S3 bucket would look like this:</p> <p><code>aws s3 cp --endpoint-url &lt;SERVER URL&gt; data.txt s3://&lt;BUCKET PATH&gt;</code></p> <p>You should be able to follow any part of the AWS S3 CLI Commands guide, remembering to add the <code>--endpoint-url</code> at the end with the server url to point things to the right server.</p> <p>Hint</p> <p>Remember as part of the Quick Setup guide, you'll want to run <code>aws configure</code> for each bucket you wish to connect to. Unless you wish to read further and setup profiles for each bucket: https://docs.aws.amazon.com/cli/latest/userguide/cli-configure-profiles.html</p>"},{"location":"Ronin/object-storage/#installing-cyberduck-profiles","title":"Installing Cyberduck profiles","text":"<p>After a bucket is created head over to the \"CONNECT INFO\" panel of the relevant storage:</p> <p> </p> <p>At the bottom will be a button to download the Cyberduck profile for the selected bucket. With the <code>.cyberduckprofile</code> file in hand import the file by double clicking it, this will open Cyberduck and present a new connection window:</p> <p> </p> <p>From this screen you can enter the AccessKeyId and SecretAccessKey into the relevant fields, please note doing so will save the credentials to your computer.</p> <p>Alternatively you can close off the screen to show the new bookmark, if you've not entered the credentials you will be asked for them upon opening the bookmark:</p> <p> </p> <p>Here you have the option not to save the credentials by un-ticking \"Add to Keychain\" on Mac or \"Save password\" on Windows.</p> <p>Given the credentials are valid you should now be able to access your bucket!</p>"},{"location":"Ronin/updates/","title":"Updates","text":"<p>Although in RCC &amp; DSH we try to take a hands off approach where possible, providing administrative level access to the systems you deploy, we as service providers have to ensure systems are kept up to date with the latest security patches.</p> <p>To do this some level of intrusive behavior is inevitable given certain updates will require a restart of the underlying operating system.</p> <p>Sadly we cannot disable this behavior without compromising security, furthermore attempts to suspend built in operating system update mechanisms may lead to termination of your instance.</p> <p>There are 2 systems in place that keep your systems updated, an automatic schedule and a task run at startup of your instances.</p>"},{"location":"Ronin/updates/#schedule","title":"Schedule","text":"<p>The scheduled updates run every Tuesday at 23:00 and are considered to be intrusive. This means that if the updates applied on this schedule require it, the host machine will reboot without warning.</p> <p>This is a requirement to ensure long lived instances aren't getting updates installed but not fully applied due to ignored reboot alerts.</p> <p>We recommend that where possible you design your workloads to expect this form of infrequent interruption, continuing from where it left off.</p>"},{"location":"Ronin/updates/#on-startup","title":"On Startup","text":"<p>As you are in control over your machines, particularly when they are and aren't running, there could be times where a machine is sat offline for an extended period of time. If this happens it could be in need of more than one critical update.</p> <p>For this reason, at the startup of any instance an intrusive update is run. Similar to the schedule this will install any missing updates and reboot if necessary.</p> <p>Note</p> <p>This can lead to some confusion when connecting to instances shortly after starting them. They might catch an update and suddenly reboot. Fear not, this is expected behavior on machines that have been off for a while.</p>"}]}